# Databricks notebook source
# MAGIC %md
# MAGIC # ğŸ­ Atelier Databricks - GMAO avec Berger Levrault
# MAGIC
# MAGIC ## ğŸ¯ Objectifs de l'atelier
# MAGIC
# MAGIC Cet atelier vous permettra de dÃ©couvrir les fonctionnalitÃ©s de base de Databricks Ã  travers un cas d'usage concret de **GMAO (Gestion de Maintenance AssistÃ©e par Ordinateur)**.
# MAGIC
# MAGIC ### Ce que vous allez apprendre :
# MAGIC
# MAGIC * **ğŸ“¥ Ingestion de donnÃ©es** : Comment charger des fichiers CSV avec Autoloader
# MAGIC * **ğŸ” Exploration de donnÃ©es** : Analyser et comprendre vos donnÃ©es de maintenance
# MAGIC * **ğŸ”§ Transformation de donnÃ©es** : Nettoyer et prÃ©parer les donnÃ©es pour l'analyse
# MAGIC * **ğŸ“Š Calcul d'indicateurs** : CrÃ©er des KPI de maintenance essentiels
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ## ğŸ“‹ ScÃ©nario de l'atelier
# MAGIC
# MAGIC Vous Ãªtes responsable de la maintenance dans une entreprise industrielle. Vous disposez de donnÃ©es sur :
# MAGIC * Les **Ã©quipements** de votre parc machine
# MAGIC * Les **ordres de travail** de maintenance
# MAGIC * Les **interventions** rÃ©alisÃ©es par les techniciens
# MAGIC
# MAGIC Votre mission : analyser ces donnÃ©es pour optimiser la maintenance et calculer des indicateurs clÃ©s.
# MAGIC
# MAGIC ---
# MAGIC
# MAGIC ## ğŸš€ PrÃªt Ã  commencer ?
# MAGIC
# MAGIC Suivez les Ã©tapes ci-dessous dans l'ordre. Chaque cellule contient des explications dÃ©taillÃ©es pour vous guider.

# COMMAND ----------

# DBTITLE 1,ğŸ“ CrÃ©ation du rÃ©pertoire de donnÃ©es
# CrÃ©ation d'un rÃ©pertoire pour stocker nos fichiers CSV
import os
from datetime import datetime, timedelta
import random

# DÃ©finition du chemin de travail
workshop_path = "/Workspace/Users/" + spark.sql("SELECT current_user()").collect()[0][0] + "/bergerlevrault-workshop"
data_path = workshop_path + "/data"

# CrÃ©ation des rÃ©pertoires si ils n'existent pas
dbutils.fs.mkdirs(data_path)

print(f"ğŸ“ RÃ©pertoire des donnÃ©es : {data_path}")
print("\nâœ… Structure des dossiers prÃªte pour l'atelier !")

# COMMAND ----------

# DBTITLE 1,ğŸ­ GÃ©nÃ©ration des donnÃ©es GMAO - Ã‰quipements
# GÃ©nÃ©ration des donnÃ©es d'Ã©quipements
import csv
import random
from datetime import datetime, timedelta

# Utilitaire: Ã©criture de CSV en plusieurs fichiers (chunking)
def write_csv_chunks(records, directory_path, base_filename, chunk_size):
    if not records:
        return
    for start_idx in range(0, len(records), chunk_size):
        chunk = records[start_idx:start_idx + chunk_size]
        part_number = (start_idx // chunk_size) + 1
        output_file = f"{directory_path}/{base_filename}_{part_number}.csv"
        with open(output_file, 'w', newline='', encoding='utf-8') as file:
            writer = csv.DictWriter(file, fieldnames=chunk[0].keys())
            writer.writeheader()
            writer.writerows(chunk)
        print(f"ğŸ“„ Fichier sauvegardÃ© : {output_file} ({len(chunk)} lignes)")

# DÃ©finition des types d'Ã©quipements typiques en industrie
equipment_types = [
    "Compresseur", "Pompe centrifuge", "Moteur Ã©lectrique", "Convoyeur", 
    "Ventilateur", "RÃ©ducteur", "Transformateur", "Groupe Ã©lectrogÃ¨ne",
    "ChaudiÃ¨re", "Ã‰changeur thermique", "Presse hydraulique", "Robot industriel"
]

locations = [
    "Atelier A", "Atelier B", "Atelier C", "Zone de stockage", 
    "Salle des machines", "Chaufferie", "Station de pompage", "Ligne de production 1",
    "Ligne de production 2", "Zone de conditionnement"
]

manufacturers = ["Siemens", "ABB", "Schneider", "Danfoss", "Grundfos", "Atlas Copco", "Bosch Rexroth"]

# ParamÃ¨tres de gÃ©nÃ©ration
EQUIPMENTS_COUNT = 500
EQUIPMENTS_CHUNK_SIZE = 100

# GÃ©nÃ©ration d'un grand nombre d'Ã©quipements
equipments_data = []
for i in range(1, EQUIPMENTS_COUNT + 1):
    install_date = datetime.now() - timedelta(days=random.randint(365, 3650))  # Entre 1 et 10 ans
    
    equipment = {
        'equipment_id': f'EQ{i:03d}',
        'equipment_name': f'{random.choice(equipment_types)} {i:02d}',
        'equipment_type': random.choice(equipment_types),
        'location': random.choice(locations),
        'manufacturer': random.choice(manufacturers),
        'model': f'MOD-{random.randint(1000, 9999)}',
        'serial_number': f'SN{random.randint(100000, 999999)}',
        'installation_date': install_date.strftime('%Y-%m-%d'),
        'criticality': random.choice(['Critique', 'Important', 'Standard']),
        'status': random.choice(['En service', 'En service', 'En service', 'En maintenance', 'ArrÃªtÃ©'])
    }
    equipments_data.append(equipment)

# Sauvegarde en plusieurs CSV (chunking)
print(f"âœ… DonnÃ©es Ã©quipements gÃ©nÃ©rÃ©es : {len(equipments_data)} enregistrements")
write_csv_chunks(equipments_data, data_path, "equipments", EQUIPMENTS_CHUNK_SIZE)
print("\nğŸ“‹ AperÃ§u des donnÃ©es :")
for i, eq in enumerate(equipments_data[:3]):
    print(f"  {i+1}. {eq['equipment_name']} - {eq['location']} - {eq['criticality']}")

# COMMAND ----------

# DBTITLE 1,ğŸ“‹ GÃ©nÃ©ration des donnÃ©es GMAO - Ordres de travail
# GÃ©nÃ©ration des ordres de travail de maintenance

work_order_types = [
    "Maintenance prÃ©ventive", "Maintenance corrective", "Inspection", 
    "RÃ©vision gÃ©nÃ©rale", "DÃ©pannage urgent", "AmÃ©lioration", "Nettoyage"
]

priorities = ["TrÃ¨s urgent", "Urgent", "Normal", "ProgrammÃ©"]
statuses = ["Ouvert", "En cours", "TerminÃ©", "AnnulÃ©"]
technicians = ["Martin Dubois", "Sophie Laurent", "Pierre Moreau", "Marie Durand", "Jean Leroy", "Claire Bernard"]

# ParamÃ¨tres de gÃ©nÃ©ration
WORK_ORDERS_COUNT = 5000
WORK_ORDERS_CHUNK_SIZE = 1000

# GÃ©nÃ©ration d'un grand nombre d'ordres de travail
work_orders_data = []
for i in range(1, WORK_ORDERS_COUNT + 1):
    # Date de crÃ©ation dans les 6 derniers mois
    creation_date = datetime.now() - timedelta(days=random.randint(1, 180))
    
    # SÃ©lection d'un Ã©quipement alÃ©atoire
    equipment = random.choice(equipments_data)
    
    # Statut et dates en fonction de l'anciennetÃ©
    if creation_date < datetime.now() - timedelta(days=30):
        status = random.choice(["TerminÃ©", "TerminÃ©", "TerminÃ©", "AnnulÃ©"])
    elif creation_date < datetime.now() - timedelta(days=7):
        status = random.choice(["En cours", "TerminÃ©", "TerminÃ©"])
    else:
        status = random.choice(["Ouvert", "En cours"])
    
    # Dates de planification et de fin
    planned_date = creation_date + timedelta(days=random.randint(1, 14))
    completion_date = None
    if status == "TerminÃ©":
        completion_date = planned_date + timedelta(days=random.randint(-2, 5))
    
    work_order = {
        'work_order_id': f'WO{i:04d}',
        'equipment_id': equipment['equipment_id'],
        'work_order_type': random.choice(work_order_types),
        'description': f'Maintenance {equipment["equipment_name"]} - {random.choice(["ContrÃ´le", "RÃ©paration", "Remplacement", "VÃ©rification"])}',
        'priority': random.choice(priorities),
        'status': status,
        'creation_date': creation_date.strftime('%Y-%m-%d'),
        'planned_date': planned_date.strftime('%Y-%m-%d'),
        'completion_date': completion_date.strftime('%Y-%m-%d') if completion_date else None,
        'assigned_technician': random.choice(technicians),
        'estimated_hours': random.randint(1, 16),
        'actual_hours': random.randint(1, 20) if status == "TerminÃ©" else None
    }
    work_orders_data.append(work_order)

# Sauvegarde en plusieurs CSV (chunking)
print(f"âœ… DonnÃ©es ordres de travail gÃ©nÃ©rÃ©es : {len(work_orders_data)} enregistrements")
write_csv_chunks(work_orders_data, data_path, "work_orders", WORK_ORDERS_CHUNK_SIZE)
print("\nğŸ“‹ AperÃ§u des donnÃ©es :")
for i, wo in enumerate(work_orders_data[:3]):
    print(f"  {i+1}. {wo['work_order_id']} - {wo['work_order_type']} - {wo['status']}")

# COMMAND ----------

# DBTITLE 1,ğŸ”§ GÃ©nÃ©ration des donnÃ©es GMAO - Interventions
# GÃ©nÃ©ration des donnÃ©es d'interventions dÃ©taillÃ©es
import builtins

intervention_types = [
    "Diagnostic", "RÃ©paration", "Remplacement piÃ¨ce", "Graissage", 
    "Nettoyage", "ContrÃ´le visuel", "Mesure vibrations", "Test fonctionnel",
    "Ã‰talonnage", "Serrage boulonnerie", "Changement filtre", "Vidange"
]

parts_used = [
    "Roulement", "Courroie", "Joint", "Filtre Ã  huile", "Filtre Ã  air", 
    "Huile hydraulique", "Graisse", "Contacteur", "Fusible", "Capteur",
    "VÃ©rin", "Flexible", "Boulon", "Ã‰crou", "Ressort"
]

# ParamÃ¨tres de gÃ©nÃ©ration
INTERVENTIONS_CHUNK_SIZE = 2000

# GÃ©nÃ©ration d'interventions pour les ordres de travail terminÃ©s
interventions_data = []
intervention_id = 1

for work_order in work_orders_data:
    if work_order['status'] == 'TerminÃ©':
        # Nombre d'interventions par ordre (1 Ã  3)
        num_interventions = random.randint(1, 3)
        
        for i in range(num_interventions):
            intervention_date = datetime.strptime(work_order['completion_date'], '%Y-%m-%d')
            if i > 0:
                intervention_date = intervention_date - timedelta(days=random.randint(0, 2))
            
            # CoÃ»t des piÃ¨ces (peut Ãªtre 0 pour certaines interventions)
            parts_cost = 0
            parts_description = ""
            if random.random() > 0.4:
                parts_cost = random.randint(10, 500)
                parts_description = random.choice(parts_used)
            
            intervention = {
                'intervention_id': f'INT{intervention_id:04d}',
                'work_order_id': work_order['work_order_id'],
                'intervention_date': intervention_date.strftime('%Y-%m-%d'),
                'technician': work_order['assigned_technician'],
                'intervention_type': random.choice(intervention_types),
                'duration_hours': builtins.round(random.uniform(0.5, 8.0), 1),
                'parts_used': parts_description,
                'parts_cost': parts_cost,
                'labor_cost': builtins.round(random.uniform(50, 400), 2),
                'comments': f'Intervention {random.choice(["rÃ©ussie", "complÃ¨te", "conforme", "satisfaisante"])}'
            }
            interventions_data.append(intervention)
            intervention_id += 1

# Sauvegarde en plusieurs CSV (chunking)
print(f"âœ… DonnÃ©es interventions gÃ©nÃ©rÃ©es : {len(interventions_data)} enregistrements")
write_csv_chunks(interventions_data, data_path, "interventions", INTERVENTIONS_CHUNK_SIZE)
print("\nğŸ“‹ AperÃ§u des donnÃ©es :")
for i, inter in enumerate(interventions_data[:3]):
    print(f"  {i+1}. {inter['intervention_id']} - {inter['intervention_type']} - {inter['duration_hours']}h")

# COMMAND ----------

# DBTITLE 1,GÃ©nÃ©ration terminÃ©e
print("\nğŸ‰ GÃ©nÃ©ration des donnÃ©es GMAO terminÃ©e !")
print(f"ğŸ“Š RÃ©sumÃ© : {len(equipments_data)} Ã©quipements, {len(work_orders_data)} ordres de travail, {len(interventions_data)} interventions")

# COMMAND ----------

# DBTITLE 1,ğŸ“‚ VÃ©rification des fichiers gÃ©nÃ©rÃ©s
# VÃ©rification que tous les fichiers ont Ã©tÃ© crÃ©Ã©s correctement
print("ğŸ“‚ Contenu du rÃ©pertoire de donnÃ©es :")
files = dbutils.fs.ls(data_path)
for file in files:
    print(f"  ğŸ“„ {file.name} ({file.size} bytes)")

print("\nâœ… Tous les fichiers CSV sont prÃªts pour l'ingestion avec Autoloader !")
print("\nğŸš€ Passons maintenant Ã  l'Ã©tape d'ingestion des donnÃ©es...")

# COMMAND ----------

# DBTITLE 1,Creation du catalog/schema/volume
# CrÃ©ation du catalog, du schema et du volume Unity Catalog
spark.sql("CREATE CATALOG IF NOT EXISTS gmao_catalog")
spark.sql("CREATE SCHEMA IF NOT EXISTS gmao_catalog.gmao_schema")
spark.sql("""
    CREATE VOLUME IF NOT EXISTS gmao_catalog.gmao_schema.gmao_volume
    COMMENT 'Volume pour les donnÃ©es GMAO'
""")

# CrÃ©ation des sous-dossiers dans le volume
dbutils.fs.mkdirs("/Volumes/gmao_catalog/gmao_schema/gmao_volume/equipments")
dbutils.fs.mkdirs("/Volumes/gmao_catalog/gmao_schema/gmao_volume/work_orders")
dbutils.fs.mkdirs("/Volumes/gmao_catalog/gmao_schema/gmao_volume/interventions")

# Copie des fichiers gÃ©nÃ©rÃ©s (plusieurs fichiers par dataset) vers le volume Unity Catalog
all_generated_files = dbutils.fs.ls(data_path)
for f in all_generated_files:
    name = f.name
    if name.startswith("equipments") and name.endswith('.csv'):
        target = f"/Volumes/gmao_catalog/gmao_schema/gmao_volume/equipments/{name}"
        dbutils.fs.cp(f.path, target)
        print(f"ğŸ“¤ CopiÃ©: {name} -> {target}")
    elif name.startswith("work_orders") and name.endswith('.csv'):
        target = f"/Volumes/gmao_catalog/gmao_schema/gmao_volume/work_orders/{name}"
        dbutils.fs.cp(f.path, target)
        print(f"ğŸ“¤ CopiÃ©: {name} -> {target}")
    elif name.startswith("interventions") and name.endswith('.csv'):
        target = f"/Volumes/gmao_catalog/gmao_schema/gmao_volume/interventions/{name}"
        dbutils.fs.cp(f.path, target)
        print(f"ğŸ“¤ CopiÃ©: {name} -> {target}")

# VÃ©rification du contenu du volume et des sous-dossiers
for folder in ["equipments", "work_orders", "interventions"]:
    print(f"\nğŸ“ Contenu du dossier {folder}:")
    files = dbutils.fs.ls(f"/Volumes/gmao_catalog/gmao_schema/gmao_volume/{folder}")
    for file in files:
        print(f"  ğŸ“„ {file.name} ({file.size} bytes)")

# COMMAND ----------

