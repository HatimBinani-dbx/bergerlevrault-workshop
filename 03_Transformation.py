# Databricks notebook source
# MAGIC %md
# MAGIC ---
# MAGIC # ğŸ”§ Ã‰tape 4 : Transformation et nettoyage des donnÃ©es
# MAGIC
# MAGIC Maintenant que nous avons explorÃ© nos donnÃ©es, nous allons les nettoyer et les transformer pour faciliter l'analyse et le calcul d'indicateurs.
# MAGIC
# MAGIC ## ğŸ¯ Objectifs de cette Ã©tape :
# MAGIC * Nettoyer les donnÃ©es (valeurs manquantes, formats)
# MAGIC * CrÃ©er des colonnes calculÃ©es utiles
# MAGIC * Joindre les tables pour une vue unifiÃ©e
# MAGIC * PrÃ©parer les donnÃ©es pour le calcul des KPI

# COMMAND ----------

catalog = 'gmao_catalog'
schema = 'gmao_schema'
volume = 'gmao_volume'
data_path = f"/Volumes/{catalog}/{schema}/{volume}"

equipments_table = spark.read.table(f"{catalog}.{schema}.equipments")
work_orders_table = spark.read.table(f"{catalog}.{schema}.work_orders")
interventions_table = spark.read.table(f"{catalog}.{schema}.interventions")

# COMMAND ----------

# DBTITLE 1,ğŸ§¹ Nettoyage des donnÃ©es d'Ã©quipements
from pyspark.sql.functions import col, when, round, datediff, current_date

# Nettoyage et enrichissement des donnÃ©es d'Ã©quipements

print("ğŸ§¹ NETTOYAGE DES DONNÃ‰ES D'Ã‰QUIPEMENTS")
print("=" * 45)

# VÃ©rification des valeurs manquantes
print("ğŸ” VÃ©rification des valeurs manquantes :")
for column in equipments_table.columns:
    null_count = equipments_table.filter(col(column).isNull()).count()
    print(f"  {column}: {null_count} valeurs manquantes")

# Enrichissement avec des colonnes calculÃ©es
equipments_clean = equipments_table.withColumn(
    "age_years", 
    round(datediff(current_date(), col("installation_date")) / 365.25, 1)
).withColumn(
    "age_category",
    when(col("age_years") < 2, "Neuf")
    .when(col("age_years") < 5, "RÃ©cent")
    .when(col("age_years") < 10, "Mature")
    .otherwise("Ancien")
).withColumn(
    "criticality_score",
    when(col("criticality") == "Critique", 3)
    .when(col("criticality") == "Important", 2)
    .otherwise(1)
)

print("\nâœ… DonnÃ©es d'Ã©quipements nettoyÃ©es et enrichies")
print("ğŸ“Š Nouvelles colonnes ajoutÃ©es : age_years, age_category, criticality_score")

# AperÃ§u des donnÃ©es enrichies
print("\nğŸ“‹ AperÃ§u des donnÃ©es enrichies :")
display(equipments_clean.select("equipment_id", "equipment_name", "age_years", "age_category", "criticality_score").limit(5))

# COMMAND ----------

# DBTITLE 1,ğŸ“‹ Nettoyage des ordres de travail
from pyspark.sql.functions import avg, sum, count

# Nettoyage et enrichissement des ordres de travail
print("ğŸ“‹ NETTOYAGE DES ORDRES DE TRAVAIL")
print("=" * 40)

# Calcul des durÃ©es et des retards
work_orders_clean = work_orders_table.withColumn(
    "planned_duration_days",
    datediff(col("planned_date"), col("creation_date"))
).withColumn(
    "actual_duration_days",
    when(col("completion_date").isNotNull(), 
         datediff(col("completion_date"), col("creation_date"))
    ).otherwise(None)
).withColumn(
    "delay_days",
    when(col("completion_date").isNotNull(),
         datediff(col("completion_date"), col("planned_date"))
    ).otherwise(None)
).withColumn(
    "is_delayed",
    when(col("delay_days") > 0, True).otherwise(False)
).withColumn(
    "priority_score",
    when(col("priority") == "TrÃ¨s urgent", 4)
    .when(col("priority") == "Urgent", 3)
    .when(col("priority") == "Normal", 2)
    .otherwise(1)
).withColumn(
    "hours_variance",
    when(col("actual_hours").isNotNull() & col("estimated_hours").isNotNull(),
         col("actual_hours").cast("double") - col("estimated_hours").cast("double")
    ).otherwise(None)
)

print("âœ… DonnÃ©es d'ordres de travail nettoyÃ©es et enrichies")
print("ğŸ“Š Nouvelles colonnes : planned_duration_days, delay_days, is_delayed, priority_score, hours_variance")

# Statistiques sur les retards
delay_stats = work_orders_clean.filter(col("completion_date").isNotNull()).agg(
    avg("delay_days").alias("retard_moyen_jours"),
    sum(when(col("is_delayed"), 1).otherwise(0)).alias("nombre_retards"),
    count("*").alias("total_termines")
)

print("\nğŸ“ˆ Statistiques sur les retards :")
display(delay_stats)

# COMMAND ----------

# DBTITLE 1,ğŸ”§ Nettoyage des interventions
from pyspark.sql.functions import min, max

# Nettoyage et enrichissement des interventions
print("ğŸ”§ NETTOYAGE DES INTERVENTIONS")
print("=" * 35)

# Enrichissement des donnÃ©es d'interventions
interventions_clean = interventions_table.withColumn(
    "total_cost",
    col("parts_cost").cast("double") + col("labor_cost").cast("double")
).withColumn(
    "cost_category",
    when(col("total_cost") < 100, "Faible")
    .when(col("total_cost") < 300, "Moyen")
    .otherwise("ElevÃ©")
).withColumn(
    "duration_category",
    when(col("duration_hours").cast("double") < 2, "Courte")
    .when(col("duration_hours").cast("double") < 6, "Moyenne")
    .otherwise("Longue")
).withColumn(
    "has_parts",
    when(col("parts_cost").cast("double") > 0, True).otherwise(False)
).withColumn(
    "cost_per_hour",
    when(col("duration_hours").cast("double") > 0, 
         round(col("total_cost") / col("duration_hours").cast("double"), 2)
    ).otherwise(None)
)

print("âœ… DonnÃ©es d'interventions nettoyÃ©es et enrichies")
print("ğŸ“Š Nouvelles colonnes : total_cost, cost_category, duration_category, has_parts, cost_per_hour")

# Statistiques sur les coÃ»ts par heure
cost_per_hour_stats = interventions_clean.filter(col("cost_per_hour").isNotNull()).agg(
    avg("cost_per_hour").alias("cout_moyen_par_heure"),
    min("cost_per_hour").alias("cout_min_par_heure"),
    max("cost_per_hour").alias("cout_max_par_heure")
)

print("\nğŸ’° Statistiques coÃ»t par heure :")
display(cost_per_hour_stats)

# COMMAND ----------

# DBTITLE 1,ğŸ”— Jointure des tables - Vue unifiÃ©e
# CrÃ©ation d'une vue unifiÃ©e en joignant toutes les tables
print("ğŸ”— CRÃ‰ATION D'UNE VUE UNIFIÃ‰E")
print("=" * 35)

# Jointure Ã©quipements + ordres de travail avec alias pour Ã©viter l'ambiguÃ¯tÃ©
equipments_workorders = equipments_clean.alias("eq").join(
    work_orders_clean.alias("wo"),
    "equipment_id",
    "inner"
).select(
    # Colonnes Ã©quipements
    col("eq.equipment_id"),
    col("eq.equipment_name"),
    col("eq.equipment_type"),
    col("eq.location"),
    col("eq.manufacturer"),
    col("eq.criticality"),
    col("eq.age_years"),
    col("eq.age_category"),
    col("eq.criticality_score"),
    
    # Colonnes ordres de travail
    col("wo.work_order_id"),
    col("wo.work_order_type"),
    col("wo.status"),
    col("wo.priority"),
    col("wo.creation_date"),
    col("wo.completion_date"),
    col("wo.assigned_technician"),
    col("wo.delay_days"),
    col("wo.is_delayed"),
    col("wo.hours_variance")
)

# Jointure avec les interventions
full_maintenance_view = equipments_workorders.join(
    interventions_clean,
    "work_order_id",
    "left"
).select(
    # Toutes les colonnes prÃ©cÃ©dentes
    col("equipment_id"),
    col("equipment_name"),
    col("equipment_type"),
    col("location"),
    col("manufacturer"),
    col("criticality"),
    col("age_years"),
    col("criticality_score"),
    col("work_order_id"),
    col("work_order_type"),
    col("status"),
    col("priority"),
    col("creation_date"),
    col("completion_date"),
    col("assigned_technician"),
    col("delay_days"),
    col("is_delayed"),
    
    # Colonnes interventions
    col("intervention_id"),
    col("intervention_type"),
    col("duration_hours"),
    col("total_cost"),
    col("cost_category"),
    col("has_parts")
)

print(f"âœ… Vue unifiÃ©e crÃ©Ã©e avec {full_maintenance_view.count()} lignes")
print(f"ğŸ“Š Nombre de colonnes : {len(full_maintenance_view.columns)}")

# AperÃ§u de la vue unifiÃ©e
print("\nğŸ“‹ AperÃ§u de la vue unifiÃ©e :")
display(full_maintenance_view.limit(5))

# COMMAND ----------

# DBTITLE 1,ğŸ’¾ Sauvegarde de la vue unifiÃ©e
# Sauvegarde de la vue unifiÃ©e en table Delta
print("ğŸ’¾ SAUVEGARDE DE LA VUE UNIFIÃ‰E")
print("=" * 35)

unified_table_path = f"{catalog}.{schema}.maintenance_unified"

# Sauvegarde en format Delta
full_maintenance_view.write \
    .format("delta") \
    .mode("overwrite") \
    .saveAsTable(unified_table_path)

print(f"âœ… Vue unifiÃ©e sauvegardÃ©e : {unified_table_path}")
print("âœ… Vue temporaire 'maintenance_unified' crÃ©Ã©e")
print("ğŸš€ DonnÃ©es prÃªtes pour le calcul des KPI !")