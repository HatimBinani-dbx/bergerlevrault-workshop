# Databricks notebook source
# MAGIC %md
# MAGIC ---
# MAGIC # ğŸ” Ã‰tape 2 : Exploration des donnÃ©es GMAO
# MAGIC
# MAGIC Maintenant que nos donnÃ©es sont ingÃ©rÃ©es, explorons-les pour mieux comprendre notre parc d'Ã©quipements et nos activitÃ©s de maintenance.
# MAGIC
# MAGIC ## ğŸ¯ Ce que nous allons dÃ©couvrir :
# MAGIC * La structure et la qualitÃ© de nos donnÃ©es
# MAGIC * La rÃ©partition des Ã©quipements par type et localisation
# MAGIC * L'Ã©tat des ordres de travail
# MAGIC * Les tendances de maintenance

# COMMAND ----------

catalog = 'gmao_catalog'
schema = 'gmao_schema'
volume = 'gmao_volume'
data_path = f"/Volumes/{catalog}/{schema}/{volume}"

equipments_table = spark.read.table(f"{catalog}.{schema}.equipments")
work_orders_table = spark.read.table(f"{catalog}.{schema}.work_orders")
interventions_table = spark.read.table(f"{catalog}.{schema}.interventions")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ğŸ” Equipements

# COMMAND ----------

# DBTITLE 1,ğŸ“Š Vue d'ensemble des Ã©quipements
from pyspark.sql.functions import desc

# Exploration des donnÃ©es d'Ã©quipements
print("ğŸ­ ANALYSE DES Ã‰QUIPEMENTS")
print("=" * 40)

# Affichage des premiÃ¨res lignes
print("ğŸ“‹ AperÃ§u des donnÃ©es :")
display(equipments_table.limit(5))

# Statistiques gÃ©nÃ©rales
print(f"\nğŸ“Š Nombre total d'Ã©quipements : {equipments_table.count()}")
print(f"ğŸ“Š Nombre de colonnes : {len(equipments_table.columns)}")

# RÃ©partition par type d'Ã©quipement
print("\nğŸ”§ RÃ©partition par type d'Ã©quipement :")
equipment_types_count = equipments_table.groupBy("equipment_type").count().orderBy(desc("count"))
display(equipment_types_count)

# COMMAND ----------

# DBTITLE 1,ğŸ“ Analyse de la localisation des Ã©quipements
# Analyse de la rÃ©partition gÃ©ographique des Ã©quipements
import matplotlib.pyplot as plt

print("ğŸ“ ANALYSE DE LOCALISATION")
print("=" * 35)

# RÃ©partition par localisation
location_stats = equipments_table.groupBy("location").count().orderBy(desc("count")).toPandas()

# Graphique en barres
plt.figure(figsize=(12, 6))
plt.bar(location_stats['location'], location_stats['count'], color='steelblue')
plt.title('RÃ©partition des Ã©quipements par localisation', fontsize=14, fontweight='bold')
plt.xlabel('Localisation')
plt.ylabel('Nombre d\'\u00e9quipements')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

print(f"\nğŸ“ Nombre de localisations diffÃ©rentes : {location_stats.shape[0]}")
print(f"ğŸ¯ Localisation avec le plus d'Ã©quipements : {location_stats.iloc[0]['location']} ({location_stats.iloc[0]['count']} Ã©quipements)")

# COMMAND ----------

# DBTITLE 1,âš ï¸ Analyse de la criticitÃ© et du statut
# Analyse de la criticitÃ© et du statut des Ã©quipements
print("âš ï¸ ANALYSE DE CRITICITÃ‰ ET STATUT")
print("=" * 40)

# RÃ©partition par criticitÃ©
criticality_stats = equipments_table.groupBy("criticality").count().orderBy(desc("count"))
print("ğŸ“Š RÃ©partition par criticitÃ© :")
display(criticality_stats)

# RÃ©partition par statut
status_stats = equipments_table.groupBy("status").count().orderBy(desc("count"))
print("\nğŸ”„ RÃ©partition par statut :")
display(status_stats)

# Analyse croisÃ©e criticitÃ© vs statut
print("\nğŸ” Analyse croisÃ©e criticitÃ© vs statut :")
cross_analysis = equipments_table.groupBy("criticality", "status").count().orderBy("criticality", desc("count"))
display(cross_analysis)

# COMMAND ----------

# MAGIC %md
# MAGIC ## ğŸ” Work Orders

# COMMAND ----------

# DBTITLE 1,ğŸ“‹ Exploration des ordres de travail
# Exploration des ordres de travail
print("ğŸ“‹ ANALYSE DES ORDRES DE TRAVAIL")
print("=" * 40)

# Vue d'ensemble
print("ğŸ“‹ AperÃ§u des ordres de travail :")
display(work_orders_table.limit(5))

print(f"\nğŸ“Š Nombre total d'ordres de travail : {work_orders_table.count()}")

# RÃ©partition par type d'ordre de travail
print("\nğŸ”§ RÃ©partition par type d'ordre de travail :")
work_order_types_count = work_orders_table.groupBy("work_order_type").count().orderBy(desc("count"))
display(work_order_types_count)

# RÃ©partition par statut
print("\nğŸ”„ RÃ©partition par statut :")
work_order_status_count = work_orders_table.groupBy("status").count().orderBy(desc("count"))
display(work_order_status_count)

# COMMAND ----------

# DBTITLE 1,ğŸ“ˆ Analyse temporelle des ordres de travail
from pyspark.sql.functions import col, date_format, weekofyear

# Analyse temporelle des ordres de travail
print("ğŸ“ˆ ANALYSE TEMPORELLE")
print("=" * 25)

# Ajout de colonnes temporelles pour l'analyse
work_orders_with_time = work_orders_table.withColumn(
    "creation_month", date_format(col("creation_date"), "yyyy-MM")
).withColumn(
    "creation_week", weekofyear(col("creation_date"))
)

# Tendance mensuelle de crÃ©ation d'ordres de travail
monthly_trend = work_orders_with_time.groupBy("creation_month").count().orderBy("creation_month")
print("ğŸ“… Tendance mensuelle de crÃ©ation d'ordres de travail :")
display(monthly_trend)

# Graphique de tendance
monthly_data = monthly_trend.toPandas()
plt.figure(figsize=(12, 6))
plt.plot(monthly_data['creation_month'], monthly_data['count'], marker='o', linewidth=2, markersize=8)
plt.title('Tendance mensuelle des ordres de travail', fontsize=14, fontweight='bold')
plt.xlabel('Mois')
plt.ylabel('Nombre d\'ordres de travail')
plt.xticks(rotation=45)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print(f"\nğŸ“Š Mois le plus chargÃ© : {monthly_data.loc[monthly_data['count'].idxmax(), 'creation_month']} ({monthly_data['count'].max()} ordres)")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ğŸ” Interventions

# COMMAND ----------

# DBTITLE 1,ğŸ”§ Exploration des interventions (SQL)
# Exploration des interventions via SQL
print("ğŸ”§ ANALYSE DES INTERVENTIONS (SQL)")
print("=" * 35)

table_interventions = f"{catalog}.{schema}.interventions"

# Vue d'ensemble (Ã©chantillon)
print("ğŸ“‹ AperÃ§u des interventions :")
display(spark.sql(f"SELECT * FROM {table_interventions} LIMIT 5"))

# Nombre total d'interventions
print("\nğŸ“Š Nombre total d'interventions :")
display(spark.sql(f"SELECT COUNT(*) AS total_interventions FROM {table_interventions}"))

# RÃ©partition par type d'intervention
print("\nğŸ”§ RÃ©partition par type d'intervention :")
display(spark.sql(
    f"""
    SELECT intervention_type, COUNT(*) AS count
    FROM {table_interventions}
    GROUP BY intervention_type
    ORDER BY count DESC
    """
))

# Statistiques sur les durÃ©es
print("\nâ±ï¸ Statistiques sur les durÃ©es d'intervention :")
display(spark.sql(
    f"""
    SELECT
      AVG(CAST(duration_hours AS DOUBLE)) AS duree_moyenne,
      MIN(CAST(duration_hours AS DOUBLE)) AS duree_min,
      MAX(CAST(duration_hours AS DOUBLE)) AS duree_max,
      STDDEV(CAST(duration_hours AS DOUBLE)) AS ecart_type
    FROM {table_interventions}
    """
))

# COMMAND ----------

# DBTITLE 1,ğŸ’° Analyse des coÃ»ts de maintenance (SQL)
# Analyse des coÃ»ts de maintenance via SQL
print("ğŸ’° ANALYSE DES COÃ›TS (SQL)")
print("=" * 25)

# Statistiques gÃ©nÃ©rales des coÃ»ts
print("ğŸ“Š Statistiques des coÃ»ts :")
display(spark.sql(
    f"""
    SELECT
      SUM(CAST(parts_cost AS DOUBLE)) AS cout_total_pieces,
      SUM(CAST(labor_cost AS DOUBLE)) AS cout_total_main_oeuvre,
      AVG(CAST(parts_cost AS DOUBLE)) AS cout_moyen_pieces,
      AVG(CAST(labor_cost AS DOUBLE)) AS cout_moyen_main_oeuvre
    FROM {table_interventions}
    """
))

# Top 10 des interventions les plus coÃ»teuses
print("\nğŸ’¸ Top 10 des interventions les plus coÃ»teuses :")
display(spark.sql(
    f"""
    SELECT
      intervention_id,
      intervention_type,
      parts_cost,
      labor_cost,
      (CAST(parts_cost AS DOUBLE) + CAST(labor_cost AS DOUBLE)) AS total_cost
    FROM {table_interventions}
    ORDER BY total_cost DESC
    LIMIT 10
    """
))

# RÃ©partition des coÃ»ts par type d'intervention
print("\nğŸ“ˆ CoÃ»t moyen par type d'intervention :")
display(spark.sql(
    f"""
    SELECT
      intervention_type,
      AVG(CAST(parts_cost AS DOUBLE) + CAST(labor_cost AS DOUBLE)) AS cout_moyen,
      COUNT(*) AS nombre_interventions
    FROM {table_interventions}
    GROUP BY intervention_type
    ORDER BY cout_moyen DESC
    """
))

# COMMAND ----------

# MAGIC %md
# MAGIC ## ğŸ” ?

# COMMAND ----------


